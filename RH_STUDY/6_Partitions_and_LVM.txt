====================================================================================
******************************* PARTITIONS & LVM ***********************************
====================================================================================
>>> PARTED <<<

parted /dev/sdb1

> mkpart
> primary
> linux-swap
> Start?0
> end?2048m

Created 4 partitions on a 5GB disk:

[root@localhost ~]# parted /dev/sde
GNU Parted 3.1
Using /dev/sde
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) print                                                            
Model: ATA VBOX HARDDISK (scsi)
Disk /dev/sde: 5369MB
Sector size (logical/physical): 512B/512B
Partition Table: msdos
Disk Flags: 

Number  Start   End     Size    Type     File system     Flags
 1      1049kB  1000MB  999MB   primary  ext4
 2      1000MB  3000MB  2000MB  primary
 3      3000MB  4000MB  1000MB  primary
 4      4000MB  5000MB  999MB   primary  linux-swap(v1)


Setting up the swap space:

[root@localhost ~]# mkswap /dev/sde4
Setting up swapspace version 1, size = 975868 KiB
no label, UUID=3d523bcb-0502-4b9c-8a77-65bb74ef5da4
[root@localhost ~]# swapon /dev/sde4

View swaps on the system:

[root@localhost ~]# cat /proc/swaps
Filename        Type    Size  Used  Priority
/dev/dm-1                               partition 839676  137848  -1
/dev/sde4                               partition 975868  0 -2

==========================================================================================
REST THE PURPOSE USING *PARTED

This changes the flag to LVM.

  # parted /dev/sdb
Run the print command. The flags column for existing partitions should be empty. Now youâ€™ll set that flag with the set command. From the commands shown here, the flags are set to use that first partition of the second drive as an LVM partition:
(parted) set 
Partition number? 1 
Flag to Invert? lvm 
New state? [on]/off on

--------------------------------------------

LOGICAL VOLUME MANAGER

Physical Volumes >> Volume Group >> Logical Volumes

/dev/sdb1        >> vg_group01   >> secretSanta

Physical         Logical
extents          extents

Physical Extents = YOUR DATA

Physical Volumme

[root@localhost ~]# pvdisplay
  --- Physical volume ---
  PV Name               /dev/sda2
  VG Name               centos
  PV Size               7.51 GiB / not usable 3.00 MiB
  Allocatable           yes 
  PE Size               4.00 MiB
  Total PE              1922
  Free PE               10
  Allocated PE          1912
  PV UUID               qZw6wm-o0kt-Fcmq-iajl-NQEP-H95Z-Xi3zjg

Logical Volume

LVM has two units: physical extents and logical extents. 

Physical extents are used when dealing with volume groups, and logical extents, with logical volumes. The logical extents always map back to a physical extent

__________________________________________________________________
CREATING A LVM PARTITION

*PVCREATE

1/ Initialise disk to be used for a physical volume:

[root@localhost ~]# pvcreate /dev/sdb1
  Physical volume "/dev/sdb1" successfully created

*PVDISPLAY

VIEW: 

[root@localhost ~]# pvdisplay /dev/sdb1
  "/dev/sdb1" is a new physical volume of "2.79 GiB"
  --- NEW Physical volume ---
  PV Name               /dev/sdb1
  VG Name               
  PV Size               2.79 GiB
  Allocatable           NO
  PE Size               0   
  Total PE              0
  Free PE               0
  Allocated PE          0
  PV UUID               b8fbTO-FgQa-PFAl-8H0p-hk2e-lWAO-fMcN2C

__________________________________________________________________
  2/ Create volume group and add physical disk to it:

[root@localhost ~]# vgcreate vg_group01 /dev/sdb1
  Volume group "vg_group01" successfully created

VIEW:

[root@localhost ~]# vgdisplay -v vg_group01
    Using volume group(s) on command line.
  --- Volume group ---
  VG Name               vg_group01
  System ID             
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  1
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                0
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               2.79 GiB
  PE Size               4.00 MiB
  Total PE              715
  Alloc PE / Size       0 / 0   
  Free  PE / Size       715 / 2.79 GiB
  VG UUID               ArhzVv-Isra-obOu-Mtz9-3Hx2-YpDS-Se4p2P
   
  --- Physical volumes ---
  PV Name               /dev/sdb1     
  PV UUID               b8fbTO-FgQa-PFAl-8H0p-hk2e-lWAO-fMcN2C
  PV Status             allocatable
  Total PE / Free PE    715 / 715

  Physical volumes are broken down into physical extents - 4MB by default.


__________________________________________________________________
3/ Create logical volume

[root@localhost ~]# lvcreate -L 2790 vg_group01
  Rounding up size to full physical extent 2.73 GiB
  Logical volume "lvol0" created.

==========================================================================================
VIEW:

[root@localhost ~]# lvdisplay vg_group01
  --- Logical volume ---
  LV Path                /dev/vg_group01/lvol0
  LV Name                lvol0
  VG Name                vg_group01
  LV UUID                lZwM2Y-TxI0-43Ib-7Slx-4ot4-aVNk-CfaCd9
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2015-06-09 18:27:22 +1200
  LV Status              available
  # open                 0
  LV Size                2.73 GiB
  Current LE             698
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2

__________________________________________________________________
See PHYSICAL >> VOLUME >> LOGICAL

**See dem physical extents down the bottom?

[root@localhost ~]# vgdisplay -v vg_group01
    Using volume group(s) on command line.
  --- Volume group ---
  VG Name               vg_group01
  System ID             
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  2
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               0
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               2.79 GiB
  PE Size               4.00 MiB
  Total PE              715
  Alloc PE / Size       698 / 2.73 GiB
  Free  PE / Size       17 / 68.00 MiB
  VG UUID               ArhzVv-Isra-obOu-Mtz9-3Hx2-YpDS-Se4p2P
   
  --- Logical volume ---
  LV Path                /dev/vg_group01/lvol0
  LV Name                lvol0
  VG Name                vg_group01
  LV UUID                lZwM2Y-TxI0-43Ib-7Slx-4ot4-aVNk-CfaCd9
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2015-06-09 18:27:22 +1200
  LV Status              available
  # open                 0
  LV Size                2.73 GiB
  Current LE             698
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
   
  --- Physical volumes ---
  PV Name               /dev/sdb1     
  PV UUID               b8fbTO-FgQa-PFAl-8H0p-hk2e-lWAO-fMcN2C
  PV Status             allocatable
  Total PE / Free PE    715 / 17

Here's where it lives:

  [root@localhost ~]# ls -ltr /dev | grep vg
  crw-------. 1 root root     10,  63 Jun  9 17:49 vga_arbiter
  drwxr-xr-x. 2 root root          60 Jun  9 18:27 vg_group01

=================================================================================
RENAME DAT thang:

  Rename all in one golden stroke ya'll:

  [root@localhost ~]# lvrename /dev/vg_group01/lvol0 /dev/vg_group01/SecretSanta
  Renamed "lvol0" to "SecretSanta" in volume group "vg_group01"


[root@localhost ~]# lvdisplay vg_group01
  --- Logical volume ---
  LV Path                /dev/vg_group01/SecretSanta

=================================================================================
RESIZE THAT THiNG

When you resize a logical volume that already contains a formatted file system, you
need to grow the file system into the new space that becomes available
__________________________________________________________________
Resize dat sucker to be smaller:

[root@localhost ~]# lvresize -L 2000 /dev/vg_group01/SecretSanta
  WARNING: Reducing active logical volume to 1.95 GiB
  THIS MAY DESTROY YOUR DATA (filesystem etc.)
Do you really want to reduce SecretSanta? [y/n]: y

  Size of logical volume vg_group01/SecretSanta changed from 2.73 GiB (698 extents) to 1.95 GiB (500 extents).
  Logical volume SecretSanta successfully resized

_________________________________________________________________
  Chuck a few extra extends on dere:

  [root@localhost ~]# lvextend -L +200 /dev/vg_group01/SecretSanta 
  Size of logical volume vg_group01/SecretSanta changed from 1.95 GiB (500 extents) to 2.15 GiB (550 extents).
  Logical volume SecretSanta successfully resized

=================================================================================
ADD ANOTHER PHYSICAL VOLUME TO EXTEND VOLUME GROUP

[root@localhost ~]# pvcreate /dev/sdb2
  Physical volume "/dev/sdb2" successfully created

_________________________________________________________________
Chuck it in the volume group:

[root@localhost ~]# vgextend vg_group01 /dev/sdb2
  Volume group "vg_group01" successfully extended

_________________________________________________________________
Now we getting somewhere - look at the bottom:

(also   VG Size               6.00 GiB)

[root@localhost ~]# vgdisplay -v vg_group01 
    Using volume group(s) on command line.
  --- Volume group ---
  VG Name               vg_group01
  System ID             
  Format                lvm2
  Metadata Areas        2
  Metadata Sequence No  6
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                1
  Open LV               0
  Max PV                0
  Cur PV                2
  Act PV                2
  VG Size               6.00 GiB
  PE Size               4.00 MiB
  Total PE              1535
  Alloc PE / Size       550 / 2.15 GiB
  Free  PE / Size       985 / 3.85 GiB
  VG UUID               ArhzVv-Isra-obOu-Mtz9-3Hx2-YpDS-Se4p2P
   
  --- Logical volume ---
  LV Path                /dev/vg_group01/SecretSanta
  LV Name                SecretSanta
  VG Name                vg_group01
  LV UUID                lZwM2Y-TxI0-43Ib-7Slx-4ot4-aVNk-CfaCd9
  LV Write Access        read/write
  LV Creation host, time localhost.localdomain, 2015-06-09 18:27:22 +1200
  LV Status              available
  # open                 0
  LV Size                2.15 GiB
  Current LE             550
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:2
   
  --- Physical volumes ---
  PV Name               /dev/sdb1     
  PV UUID               b8fbTO-FgQa-PFAl-8H0p-hk2e-lWAO-fMcN2C
  PV Status             allocatable
  Total PE / Free PE    715 / 165
   
  PV Name               /dev/sdb2     
  PV UUID               e9VSlX-dDVz-yd1p-mdBR-OZeJ-9hzJ-zp2fyw
  PV Status             allocatable
  Total PE / Free PE    820 / 820


_________________________________________________________________
lvresize/ lvreduce

lvresize -L 2000 /dev/sdb1/secretSanta

If you add another disk using vgextend vg_group01 /dev/sdb2 then use lvresize to boost that sucker up. E.g. if 4G to start with then add another 500MB disk then:

lvresize -L 4550 /dev/mockinbird/crow

_________________________________________________________________
Remove the Disk That was added to volume group

vgreduce vg_group01 /dev/sdb2

=================================================================================
MIGRATING DATA

Physical Extents = YOUR DATA

So we have:

[root@localhost ~]# tree /dev/vg_group01/
/dev/vg_group01/
â””â”€â”€ SecretSanta -> ../dm-2

with /dev/sdb1 and /dev/sdb2 added.. 

Can copy from one to the other with pvmove command so if /dev/sdb2 is dying:

pvmove /dev/sdb1 /dev/sdb2



   Device Boot      Start         End      Blocks   Id  System
/dev/sdb1               1     5859375     2929687+  83  Linux
/dev/sdb2         5859376    12582911     3361768   83  Linux


=================================================================================
REMOVING DATA/ LVs and PVs

_________________________________________________________________
1/ Remove Logical Volume

lvremove /dev/vg_group01/secretSanta


2/ Remove Volume Group

vgremove vg_group01


Remove Both LV and VG Together

vgremove -f vg_group01

3/ Wipe Out Physical Disks

pvremove /dev/sdb1

=================================================================================
SETTING UP RAID

RAID 1: Mirroring
RAID 5: Striping with parity (25% used for parity bit)

Add 3 partitions into the array:

[root@localhost ~]# mdadm -Cv /dev/md0 --level=5 -n3 /dev/sdd1 /dev/sdd2 /dev/sde1

mdadm: You have listed more devices (4) than are in the array(3)!
[root@localhost ~]# mdadm -Cv /dev/md0 --level=5 -n3 /dev/sdd1 /dev/sdd2 /dev/sde1 
mdadm: layout defaults to left-symmetric
mdadm: layout defaults to left-symmetric
mdadm: chunk size defaults to 512K
mdadm: size set to 1951744K
mdadm: largest drive (/dev/sdd2) exceeds size (1951744K) by more than 1%

Continue creating array? yes
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.

_________________________________________________________________
Created successfully:

[root@localhost ~]# mdadm -D /dev/md0
/dev/md0:
        Version : 1.2
  Creation Time : Mon Jun 15 17:03:00 2015
     Raid Level : raid5
     Array Size : 3903488 (3.72 GiB 4.00 GB)
  Used Dev Size : 1951744 (1906.32 MiB 1998.59 MB)
   Raid Devices : 3
  Total Devices : 3
    Persistence : Superblock is persistent

    Update Time : Mon Jun 15 17:03:11 2015
          State : clean 
 Active Devices : 3
Working Devices : 3
 Failed Devices : 0
  Spare Devices : 0

         Layout : left-symmetric
     Chunk Size : 512K

           Name : localhost.localdomain:0  (local to host localhost.localdomain)
           UUID : 855daf19:12025a2e:b22f4263:b673e5a3
         Events : 18

    Number   Major   Minor   RaidDevice State
       0       8       49        0      active sync   /dev/sdd1
       1       8       50        1      active sync   /dev/sdd2
       3       8       65        2      active sync   /dev/sde1

Check status

_________________________________________________________________
[root@localhost ~]# cat /proc/mdstat
Personalities : [raid6] [raid5] [raid4] 
md0 : active raid5 sde1[3] sdd1[0] sdd2[1]
      3903488 blocks super 1.2 level 5, 512k chunk, algorithm 2 [3/3] [UUU]
      
unused devices: <none>

_________________________________________________________________
Fail a device in the group:

mdadm /dev/md0 -f /dev/sbdb1

Show the status:

[root@localhost ~]# mdadm -D /dev/md0
/dev/md0:
        Version : 1.2
  Creation Time : Mon Jun 15 17:03:00 2015
     Raid Level : raid5
     Array Size : 3903488 (3.72 GiB 4.00 GB)
  Used Dev Size : 1951744 (1906.32 MiB 1998.59 MB)
   Raid Devices : 3
  Total Devices : 3
    Persistence : Superblock is persistent

    Update Time : Mon Jun 15 17:31:31 2015
          State : clean, degraded 
 Active Devices : 2
Working Devices : 2
 Failed Devices : 1
  Spare Devices : 0

         Layout : left-symmetric
     Chunk Size : 512K

           Name : localhost.localdomain:0  (local to host localhost.localdomain)
           UUID : 855daf19:12025a2e:b22f4263:b673e5a3
         Events : 20

    Number   Major   Minor   RaidDevice State
       0       8       49        0      active sync   /dev/sdd1
       1       8       50        1      active sync   /dev/sdd2
       4       0        0        4      removed

       3       8       65        -      faulty   /dev/sde1

_________________________________________________________________
Remove disk from array:

[root@localhost ~]# mdadm /dev/md0 -r /dev/sde1
mdadm: hot removed /dev/sde1 from /dev/md0

See the status:

    Number   Major   Minor   RaidDevice State
       0       8       49        0      active sync   /dev/sdd1
       1       8       50        1      active sync   /dev/sdd2
       4       0        0        4      removed

_________________________________________________________________
Add a new disk:

mdadm /dev/md0 -a /dev/sdb1

Stop the array:

mdadm -Sv /dev/md0

_________________________________________________________________
Remove RAID array:

mdadm -remove /dev/md0


Then remove partitions:

pvremove /dev/sdb1

*** Must creat /boot on RAID 1